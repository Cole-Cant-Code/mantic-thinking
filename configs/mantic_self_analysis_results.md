# **Mantic Self-Analysis Results**
## The Framework Analyzing Itself

*Generated by `scripts/self_analysis.py` using the mantic 4-layer hierarchical reasoning framework.*

---

## Overall Health

| Metric | Value |
|--------|-------|
| **Overall Score** | 0.66 |
| **Strongest Column** | Documentation (0.74) |
| **Weakest Column** | Testing (0.52) |
| **Friction M-Score** | 0.679 (aligned — gap below threshold) |
| **Emergence Window** | NOT ALIGNED (testing at 0.52 blocks) |
| **Temporal Status** | Structural (L3/L4 heavy) |
| **Kernel Integrity** | PASS |

---

## Column Averages (Weighted: Micro=0.15, Meso=0.25, Macro=0.35, Meta=0.25)

| Column | Score | Status |
|--------|-------|--------|
| Architecture | 0.71 | Strong core, weak extensibility |
| Implementation | 0.75 | Deterministic and verified |
| Testing | 0.52 | Weakest — emergence tools untested |
| Documentation | 0.74 | Rich configs, no living docs |
| Developer Experience | 0.57 | Good ergonomics, no production packaging |

---

## Layer Detail Grid

| Layer | Architecture | Implementation | Testing | Documentation | Developer Exp |
|-------|:---:|:---:|:---:|:---:|:---:|
| **Micro** | 0.65 | 0.85 | 0.70 | 0.85 | 0.80 |
| **Meso** | 0.75 | 0.70 | 0.50 | 0.90 | 0.75 |
| **Macro** | 0.85 | 0.90 | 0.55 | 0.85 | 0.55 |
| **Meta** | 0.50 | 0.55 | 0.40 | 0.35 | 0.30 |

**Observation:** Micro and Macro are consistently strong across columns. Meta is weak everywhere — the codebase has mature core logic but underdeveloped long-term evolution mechanisms.

---

## Codebase Tool Results

### Friction: Layer Conflict Detector

| Field | Value |
|-------|-------|
| M-Score | 0.679 |
| Conflict Type | aligned (gap 0.232 < threshold 0.35) |
| Bottleneck | testing |
| Alert | None (close to triggering confidence_debt) |

The max gap (0.232) is below the 0.35 threshold, meaning no formal alert triggers. However, testing is clearly the weakest link and the gap between implementation (0.75) and testing (0.52) is approaching the threshold.

### Emergence: Alignment Window Detector

| Field | Value |
|-------|-------|
| M-Score | 0.681 |
| Window Detected | **No** |
| Alignment Floor | 0.522 (testing) |
| Status | testing below 0.65 threshold |

The codebase is **not** in an alignment window. Testing at 0.52 blocks the emergence signal. Raising testing above 0.65 would open a FAVORABLE window for major changes.

---

## Analogical Domain Mappings

### Cyber Attribution Resolver → Codebase Confidence
- **Mapping:** technical=Architecture, threat_intel=Testing, operational=Implementation, geo=Documentation
- **Result:** Confidence=high, M=0.679
- **Interpretation:** Despite testing weakness, the overall quality profile doesn't trigger an "attribution gap." The codebase is coherent enough that its quality claims are believable.

### Military Friction Forecast → Operational Friction
- **Mapping:** maneuver=DX, intelligence=Documentation, sustainment=Testing, political=Architecture
- **Result:** M=0.629, Bottleneck=sustainment (Testing)
- **Interpretation:** "Tactical success constrained by logistics." The codebase can maneuver (add features) but testing sustainment limits how fast it can move safely.

### Climate Resilience Multiplier → Leverage Points
- **Mapping:** atmospheric=Architecture, ecological=Implementation, infrastructure=Testing, policy=Documentation
- **Result:** Window NOT detected. Benefits limited to 3 of 4 domains.
- **Interpretation:** Testing is the infrastructure bottleneck. Improving it would have the highest leverage across the system.

### Finance Confluence Alpha → Release Readiness
- **Mapping:** technical=Architecture, macro=Documentation, flow=DX, risk=Testing
- **Result:** Window NOT detected. M=0.632.
- **Interpretation:** Not at "release-ready confluence." Risk (testing) and flow (DX/packaging) are both below optimal levels.

---

## Boundary Weaver Pattern Detection

### 1. Translation Gap (Medium-High)
**Signal:** Configs describe multi-column reasoning with coupling matrices C_ij, but code only implements single-column 4-input tools.

**Fix:** Either build multi-column orchestration in code, or explicitly document that configs are aspirational reasoning scaffolds — not implementation specifications.

### 2. Hidden Bottleneck (Low-Medium)
**Signal:** All 3 non-OpenAI adapters (Claude, Kimi, Gemini) inherit from openai_adapter.py's TOOL_MAP. OpenAI adapter is the throughput constraint.

**Fix:** Extract shared base_adapter.py. Each adapter owns its own schema generation while sharing tool execution.

### 3. Overload Blindspot (Medium)
**Signal:** Emergence tools have no dedicated test classes. Only friction tools get individual validation. Emergence is the "quiet silo" that breaks unnoticed.

**Fix:** Add dedicated emergence test classes mirroring friction test structure.

### 4. Cascade Risk (Low)
**Signal:** mantic_kernel.py is a single point of failure. verify_kernel_integrity() exists but is only called in tests, not at module import time.

**Fix:** The kernel is well-protected (IMMUTABLE label, integrity check). Consider calling verify_kernel_integrity() in core/__init__.py as an import-time guard.

---

## Coupling Matrix

| Coupling | Type | Strength | Note |
|----------|------|:---:|------|
| Architecture × Testing | CONFLICT | -0.4 | Strong architecture, weak testing. Half-blind validation. |
| Implementation × Documentation | REINFORCE | +0.8 | Code does what docs describe. Strongest coupling. |
| Architecture × Developer Exp | BOTTLENECK | -0.3 | No extensibility pattern constrains production readiness. |
| Documentation × Architecture | TRANSLATION GAP | -0.5 | Configs describe multi-column; code is single-column. |
| Testing × Implementation | CONFIDENCE DEBT | -0.4 | Good code asserted structurally, not empirically for emergence. |

---

## Explicit Framework Output

```
[Column: Architecture] (Score: 0.71)
L1: File structure consistent, sys.path.insert hacking present
L2: Clean module tree, adapter chain through single adapter
L3: Strong core/tools/adapters separation, immutability contract
L4: No plugin pattern, adding domains requires 5+ file edits
Dominant: L3

[Column: Implementation] (Score: 0.75)
L1: Excellent input validation and clamping
L2: Good kernel reuse, WEIGHTS dict/list inconsistency
L3: Deterministic, verified, cross-model consistent
L4: sys.path hacking debt, no proper packaging
Dominant: L3

[Column: Testing] (Score: 0.52)
L1: Reasonable per-tool test cases (friction suite)
L2: Minimal smoke tests added for internal codebase tools; emergence tools still lack dedicated per-domain test classes (half-blind)
L3: Cross-model consistency test is strong
L4: No property-based testing, no CI/CD
Dominant: L3

[Column: Documentation] (Score: 0.74)
L1: Excellent docstrings with Args/Returns/Example
L2: 14 config docs with rich consistent patterns
L3: README + SKILL.md cover all platforms
L4: No CHANGELOG, no ADRs, no migration guides
Dominant: L2

[Column: Developer Experience] (Score: 0.57)
L1: Simple install, clear error messages
L2: Consistent adapter APIs, good discoverability
L3: 4 adapters + Ollama, no deployment packaging
L4: No CONTRIBUTING.md, no community governance
Dominant: L2

[Coupling: Architecture × Testing]
Conflict: Architecture (0.71) vs Testing (0.52)
Resolution: Invest in emergence tool tests before adding features

[Coupling: Implementation × Documentation]
Reinforcement: Both strong (0.75, 0.74)
The documentation accurately describes the implementation

[Coupling: Architecture × Developer Experience]
Bottleneck: Architecture-Meta (extensibility=0.50) constrains DX-Macro (production=0.55)
Resolution: Create tool registry/template system
```

**Temporal Status:** Structural (L3/L4 heavy). The codebase is mature in core logic but needs infrastructure investment.

---

## Prioritized Recommendations

| Priority | Action | Rationale |
|:---:|--------|-----------|
| **HIGH** | Add emergence tool test classes | Testing-Meso is 0.50. Minimal smoke tests exist for internal tools only; per-domain emergence tests still needed. |
| **HIGH** | Standardize WEIGHTS format (dict everywhere) | Implementation-Meso inconsistency between friction (dict) and emergence (list). |
| MEDIUM | Add CI/CD pipeline | Testing-Macro is 0.55. Cross-model test exists but isn't automated. |
| MEDIUM | Create proper Python packaging (pyproject.toml) | Implementation-Meta is 0.55. sys.path.insert is fragile. |
| MEDIUM | Document the config/code translation gap | Documentation-Architecture coupling is -0.5 due to multi-column aspiration. |
| LOW | Add CHANGELOG.md and ADRs | Documentation-Meta is 0.35. No living documentation strategy. |
| LOW | Create CONTRIBUTING.md | DX-Meta is 0.30. No community onboarding path. |
| LOW | Extract base_adapter.py from openai_adapter | Architecture-Meso coupling concern. All adapters depend on one. |

---

*End of Self-Analysis Results*
